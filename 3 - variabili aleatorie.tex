\chapter{Variabili aleatorie e valore atteso}

\section{Variabili aleatorie}

Con le variabili aleatorie si assegna la probabilit\`{a} ai valori possibili. 

Esempio dei due dadi: 
La probabilit\`{a} che il risultato della somma sia 3 si scrive cos\`{i}
\begin{equation}
   P(\{X = 3\}) = P\{(2,1),(1,2)\} 
\end{equation}

Quindi si hanno 2 casi favorevoli su 36 totali, che porta la probabilit\`{a} al valore di $0.055$. 

\section{Variabili aleatorie discrete e continue}

Le variabili aleatorie che prendono valori da insiemi finiti o numerabili prendono il nome di \textbf{discrete}. 

In alternativa le variabili non numerabili prendono il nome di \textbf{continue} e sono tutti quei valori 
che fanno parte dei numeri reali. 

\subsection{Funzione di ripartizione}

\begin{equation}
   F(x) = P(X \leq x) 
\end{equation}

La funzione $F(x)$ rappresenta la probabilit\`{a} con la quale la variabile aleatorie $X$ sia $\leq$ di $x$. 

La notazione $X \sim F$ indica che $F$ \`{e} la funzione di ripartizione di $X$. 

\subsection{Variabili aleatorie discrete e continue}
Se $X$ \`{e} una variabile aleatoria discreta, la sua \textbf{funzione id massa di probabilit\`{a}(PMF)} \`{e}: 
\begin{equation}
   p(a) = P(X=a) 
\end{equation}


\subsection{Funzioni di densit\`{a} di probabilit\`{a} di $X$(PDF)}

\begin{equation}
    1 = P(X \in \Re) = \displaystyle\int_{-\infty}^{+\infty} f(x)dx
\end{equation}

dove il limiti di integrazione sono dati dal range dei dati che stiamo considerando. 


ESEMPIO:
Variabile aleatoria $X$ con PDF:

\begin{equation}
    f(x) = \begin{cases}
        c(4x - 2x^2) \indent  0 < x < 2 \\
        0 \indent \indent \indent \indent else
    \end{cases}
\end{equation}

Per ottenere $c$:
\begin{equation}
    1 = c \displaystyle\int_{0}^{2} (4x - 2x^2)dx = c\Bigg[2x^2 - 2\displaystyle\frac{x^3}{3}\Bigg]_{x=0}^{x=2} = c \displaystyle\frac{8}{3}
\end{equation}
$c = \displaystyle\frac{3}{8}$

\section{Coppie di vettori di variabili aleatorie}


Utili a valutare la relazione tra variabili aleatorie. 

\subsection{Distribuzione congiunta per variabili aleatorie continue}


$X$ e $Y$ sono congiuntamente continue se esiste $f(x,y) > 0$ definita per tutti 
$x,y$ tale che ogni sottoinsieme $C$ del piano cartesiano sia:
\begin{equation}
   P((x, y) \in C) = \iint_{x,y \in C} f(x, y)dxdy
\end{equation}

Dove con $f(x, y)$ si intende la densit\`{a} congiunta. 


Facendo vari giri matematici si ottiene:
\begin{equation}
   \displaystyle\int_{b}^{b + db}\displaystyle\int_{a}^{a + da} f(x, y)dxdy \simeq f(a, b)dadb 
\end{equation}

\textbf{Vale solo se $da$ e $db$ sono molto piccoli e $f(a, b)$ \`{e} continua in $(a, b)$}. 


\subsection{Variabili aleatorie indipendenti}


\begin{equation}
   P(X \in A, Y \in B) = P(X \in A) P(Y \in B) 
\end{equation}

\subsection{Generalizzazione a pi\`{u} variabili aleatorie}

Ripartizione:
\begin{equation}
   F(a_1, a_2, \dots, a_n) = P(x_1 \leq a_1, \dots, x_n \leq a_n) 
\end{equation}

Se sono variabili discrete:
\begin{equation}
   p(x_1, x_2, \dots, x_n) = P(X_1 = x_1, X_2 = x_2, \dots, X_n = x_n) 
\end{equation}


Se sono continua devo usare le funzioni con gli integrali mega in sbatti. 

\subsection{Indipendenza}

Infinite variabili aleatorie sono indipendenti se ogni loro sottogruppo finito \`{e} formato da 
variabili aleatorie indipendenti. 

\textbf{mancano la densita condizionale e la distribuzioen condizionale}

\section{Valore atteso}

$X$ variabili aleatoria con valori $x_1, \dots$, il valore atteso di $X$:

\begin{equation}
   E[X] = \displaystyle\sum_{i} x_i P(X = x_i) 
\end{equation}

Il valore della sommatoria deve converge ad un numero inferiore a infinito. 

Praticamente la media pesata dei possibili valori di $X$, con pesi dati dalle probabilit\`{a}. 

$E[X]$ viene chaimata media di $X$ oppure aspettazione (expectation). 


\section{Proprietà del valore atteso}

Se $X$ è una variabile aleatoria discreta con funzione di massa di probabilità $p$, allora, per ogni 
funzione reale $g$:

\begin{equation}
    E[g(X)] = \displaystyle\sum_{x} g(x)p(x) 
\end{equation}


Se $X$ è una variabile aleatoria continua con funzione di densità di probabilità $f$, allora, per ogni 
funzione reale $g$:

\begin{equation}
    E[g(X)] = \displaystyle\int_{-\infty}^{+\infty} g(x)f(x)dx 
\end{equation}


\section{Variana}

Misura della variabilità della variabile aleatoria, la media $E[X]$ rappresenta il baricentro ma non 
è sufficiente. 

Sia $X$ una variabile aleatoria con media $\mu$, la varianza di $X$ si denota con $Var(X)$:
\begin{equation}
    Var(X) = E[(X-\mu)^2] 
\end{equation}


Però spesso viene più comoda la seguente formula:
\begin{equation}
    Var(X) = E[X^2] - E[X]^2 
\end{equation}




\subsection{Deviazione standard}
per calcolare la deviazioen standard basta:
\begin{equation}
    \sqrt{Var(X)} 
\end{equation}


\section{La covarianza e la varianza della somma di variabili aleatorie}

Avendo due variabili aleatorie $X$ e $Y$ con media $\mu_X$ e $\mu_Y$, la loro covarianza se esiste è:
\begin{equation}
    Cov(X, Y) = E[(X - \mu_X) (Y - \mu_Y)] 
\end{equation}


\textbf{Proprietà}
\begin{itemize}
    \item $Cov(X, Y) = Cov(Y, X)$ 
    \item $Cov(X, X) = Var(X)$ 
    \item $Cov(aX, Y) = a Cov(X, Y) = Cov(X, aY)$ 
\end{itemize}

\subsection{Coefficiente di correlazione lineare}

\begin{equation}
    Corr(X, Y) = \displaystyle\frac{Cov(X, Y)}{\sqrt{Var(X)Var(Y)}} 
\end{equation}

\section{La funzione generatrice dei momenti}




